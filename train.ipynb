{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b66e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertModel, BertTokenizer, BertConfig, get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BERT_PATH = \"bert_model/\"    # 该文件夹下存放三个文件（'vocab.txt', 'pytorch_model.bin', 'config.json'）\n",
    "# DATA_PATH = \"data/tags_data.txt\"\n",
    "DATA_PATH = \"data/test_data.txt\"\n",
    "MAX_LEN = 64\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e36253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert_Model(nn.Module):\n",
    "    def __init__(self, bert_path, classes=2):\n",
    "        super(Bert_Model, self).__init__()\n",
    "        self.config = BertConfig.from_pretrained(bert_path)  # 导入模型超参数\n",
    "        self.bert = BertModel.from_pretrained(bert_path)     # 加载预训练模型权重\n",
    "        self.fc = nn.Linear(self.config.hidden_size, classes)  # 直接分类\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "        out_pool = outputs[1]   # 池化\n",
    "        logit = self.fc(out_pool) # 线性模型二分类\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e41f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7dc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    input_ids, input_masks, input_types, tag_labels = [], [], [], []\n",
    "\n",
    "    with open(DATA_PATH, encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f):\n",
    "            tags, labels = line.strip().split(\"\\t\")\n",
    "            encode_dict = tokenizer.encode_plus(text=tags, max_length=MAX_LEN,\n",
    "                                                    padding=\"max_length\", truncation=True)\n",
    "\n",
    "            input_ids.append(encode_dict[\"input_ids\"])\n",
    "            input_types.append(encode_dict[\"token_type_ids\"])\n",
    "            input_masks.append(encode_dict[\"attention_mask\"])\n",
    "            tag_labels.append(int(labels))\n",
    "\n",
    "    all_data = (input_ids, input_masks, input_types, tag_labels)\n",
    "    unit = len(tag_labels) // 10\n",
    "    train_data = list(map(lambda x: x[:unit*8], all_data))\n",
    "    valid_data = list(map(lambda x: x[unit*8:unit*9], all_data))\n",
    "    test_data = list(map(lambda x: x[unit*9:], all_data))\n",
    "\n",
    "    return train_data, valid_data, test_data\n",
    "train_data, valid_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20512bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(*tuple(map(torch.LongTensor, train_data)))\n",
    "train_sampler = RandomSampler(train_dataset)  \n",
    "train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_dataset = TensorDataset(*tuple(map(torch.LongTensor, valid_data)))\n",
    "valid_sampler = RandomSampler(valid_dataset)  \n",
    "valid_loader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(*tuple(map(torch.LongTensor, test_data)))\n",
    "test_sampler = RandomSampler(test_dataset)  \n",
    "test_loader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_number(model):\n",
    "    #  打印模型参数量\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return 'Total parameters: {}, Trainable parameters: {}'.format(total_num, trainable_num)\n",
    "\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "model = Bert_Model(BERT_PATH).to(DEVICE)\n",
    "print(get_parameter_number(model))\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4) #AdamW优化器\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=len(train_loader),\n",
    "                                            num_training_steps=EPOCHS*len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d98dfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型性能，在验证集上\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    val_true, val_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, att, tpe, y) in (enumerate(data_loader)):\n",
    "            y_pred = model(ids.to(device), att.to(device), tpe.to(device))\n",
    "            y_pred = torch.argmax(y_pred, dim=1).detach().cpu().numpy().tolist()\n",
    "            val_pred.extend(y_pred)\n",
    "            val_true.extend(y.squeeze().cpu().numpy().tolist())\n",
    "    \n",
    "    return accuracy_score(val_true, val_pred)  #返回accuracy\n",
    "\n",
    "\n",
    "# 测试集没有标签，需要预测提交\n",
    "def predict(model, data_loader, device):\n",
    "    model.eval()\n",
    "    val_true, val_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, att, tpe, y) in tqdm(enumerate(data_loader)):\n",
    "            y_pred = model(ids.to(device), att.to(device), tpe.to(device))\n",
    "            y_pred = torch.argmax(y_pred, dim=1).detach().cpu().numpy().tolist()\n",
    "            val_pred.extend(y_pred)\n",
    "            val_true.extend(y.squeeze().cpu().numpy().tolist())\n",
    "\n",
    "    print(\"\\n Test Accuracy = {} \\n\".format(accuracy_score(val_true, val_pred)))\n",
    "    print(classification_report(val_true, val_pred, digits=4))\n",
    "\n",
    "\n",
    "def train_and_eval(model, train_loader, valid_loader, \n",
    "                   optimizer, scheduler, device, epoch):\n",
    "    best_acc = 0.0\n",
    "    patience = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for i in range(epoch):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        print(\"***** Running training epoch {} *****\".format(i+1))\n",
    "        train_loss_sum = 0.0\n",
    "        for idx, (ids, att, tpe, y) in enumerate(train_loader):\n",
    "            ids, att, tpe, y = ids.to(device), att.to(device), tpe.to(device), y.to(device)  \n",
    "            y_pred = model(ids, att, tpe)\n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()   # 学习率变化\n",
    "            \n",
    "            train_loss_sum += loss.item()\n",
    "            if (idx + 1) % (len(train_loader)//5) == 0:    # 只打印五次结果\n",
    "                print(\"Epoch {:04d} | Step {:04d}/{:04d} | Loss {:.4f} | Time {:.4f}\".format(\n",
    "                          i+1, idx+1, len(train_loader), train_loss_sum/(idx+1), time.time() - start))\n",
    "                # print(\"Learning rate = {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "\n",
    "        \"\"\"验证模型\"\"\"\n",
    "        model.eval()\n",
    "        acc = evaluate(model, valid_loader, device)  # 验证模型的性能\n",
    "        ## 保存最优模型\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), \"best_bert_model.pth\") \n",
    "        \n",
    "        print(\"current acc is {:.4f}, best acc is {:.4f}\".format(acc, best_acc))\n",
    "        print(\"time costed = {}s \\n\".format(round(time.time() - start, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_eval(model, train_loader, valid_loader, optimizer, scheduler, DEVICE, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a032b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy = 0.85 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.7317    0.8333        41\n",
      "           1     0.7755    0.9744    0.8636        39\n",
      "\n",
      "    accuracy                         0.8500        80\n",
      "   macro avg     0.8716    0.8530    0.8485        80\n",
      "weighted avg     0.8740    0.8500    0.8481        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_bert_model.pth\"))\n",
    "pred_test = predict(model, test_loader, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65cd59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = \"html head meta meta meta meta meta meta link meta link link link link link link title meta meta meta meta meta meta link link meta meta meta meta meta meta meta meta meta meta meta meta meta meta meta meta meta script script link meta meta meta meta meta meta body div section div div div script span a div h1 span img a a nav ul li a ul li a li a li a li a li a li a li a li a li a li a li a li a li a li a ul li a li a li a li a li a li a li a ul li a li a li a li a li a li a li a li a li a li a li a li a ul li a li a li a li a li a li span section div div img img div div div div div div h1 span p input a p a section div div div div div div div div div div h2 p br br p a section div div div div div div div div div div h2 p p p a footer section div div div div ul li a li a li a li a span div ul li a span span a span span a span span section div div div h5 ul li a li a li a li a li a li a li a li a li a li a li a li a div h5 ul li a li a li a li a li a li a div h5 ul li a li a li a li a li a li a li a li a li a li a li a div h5 ul li a li a li a li a li a div a div div br br p b hr div div small span span a a a small a a a section a div div div h6 section div div div div div h3 p a script script script script script script script script noscript img script script script script\"\n",
    "\n",
    "encode_dict = tokenizer.encode_plus(text=tags, max_length=MAX_LEN,\n",
    "                                                padding=\"max_length\", truncation=True)\n",
    "\n",
    "input_ids = encode_dict[\"input_ids\"]\n",
    "input_types = encode_dict[\"token_type_ids\"]\n",
    "input_masks = encode_dict[\"attention_mask\"]\n",
    "result = model(torch.LongTensor([input_ids, ]), torch.LongTensor([input_types, ]), torch.LongTensor([input_masks, ]))\n",
    "torch.argmax(result, dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
